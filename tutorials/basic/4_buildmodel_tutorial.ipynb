{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bced14e",
   "metadata": {},
   "source": [
    "# Construir la Red Neuronal\n",
    "\n",
    "Las redes neuronales se componen de capas/módulos que realizan operaciones en datos.\n",
    "El espacio de nombres [torch.nn](https://pytorch.org/docs/stable/nn.html) proporciona todos los bloques de construcción que necesitas para\n",
    "construir tu propia red neuronal. Cada módulo en PyTorch es una subclase de [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
    "Una red neuronal es un módulo en sí mismo que consiste en otros módulos (capas). Esta estructura anidada permite\n",
    "construir y gestionar arquitecturas complejas fácilmente.\n",
    "\n",
    "En las siguientes secciones, construiremos una red neuronal para clasificar imágenes en el conjunto de datos FashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4981d4",
   "metadata": {},
   "source": [
    "## Obtener Dispositivo para Entrenamiento\n",
    "\n",
    "Queremos poder entrenar nuestro modelo en un [acelerador](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
    "como CUDA, MPS, MTIA, o XPU. Si el acelerador actual está disponible, lo usaremos. De lo contrario, usamos la CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dda1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0131f10",
   "metadata": {},
   "source": [
    "## Definir la Clase\n",
    "\n",
    "Definimos nuestra red neuronal heredando de ``nn.Module``, e\n",
    "inicializamos las capas de la red neuronal en ``__init__``. Cada subclase de ``nn.Module`` implementa\n",
    "las operaciones en datos de entrada en el método ``forward``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62513600",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68823c83",
   "metadata": {},
   "source": [
    "Creamos una instancia de ``NeuralNetwork``, la movemos al ``device``, e imprimimos\n",
    "su estructura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0507e5fc",
   "metadata": {},
   "source": [
    "Para usar el modelo, le pasamos los datos de entrada. Esto ejecuta el ``forward`` del modelo,\n",
    "junto con algunas [operaciones en segundo plano](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866).\n",
    "¡No llames a ``model.forward()`` directamente!\n",
    "\n",
    "Llamar al modelo con la entrada devuelve un tensor bidimensional con dim=0 correspondiente a cada salida de 10 valores predichos sin procesar para cada clase, y dim=1 correspondiente a los valores individuales de cada salida.\n",
    "Obtenemos las probabilidades de predicción pasándolo a través de una instancia del módulo ``nn.Softmax``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107981ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79306fa4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Capas del Modelo\n",
    "\n",
    "Desglosemos las capas en el modelo FashionMNIST. Para ilustrarlo,\n",
    "tomaremos un minilote de muestra de 3 imágenes de tamaño 28x28 y veremos qué le sucede mientras\n",
    "lo pasamos a través de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae174bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a020359",
   "metadata": {},
   "source": [
    "### nn.Flatten\n",
    "\n",
    "Inicializamos la capa [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html)\n",
    "para convertir cada imagen 2D de 28x28 en un arreglo contiguo de 784 valores de píxeles (\n",
    "la dimensión del minilote (en dim=0) se mantiene)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcfa1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abed8a8",
   "metadata": {},
   "source": [
    "### nn.Linear\n",
    "\n",
    "La [capa lineal](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)\n",
    "es un módulo que aplica una transformación lineal en la entrada usando sus pesos y sesgos almacenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3174a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ef2786",
   "metadata": {},
   "source": [
    "### nn.ReLU\n",
    "\n",
    "Las activaciones no lineales son las que crean las asignaciones complejas entre las entradas y salidas del modelo.\n",
    "Se aplican después de las transformaciones lineales para introducir *no linealidad*, ayudando a las redes neuronales\n",
    "a aprender una amplia variedad de fenómenos.\n",
    "\n",
    "En este modelo, usamos [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html) entre nuestras\n",
    "capas lineales, pero hay otras activaciones para introducir no linealidad en tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937bee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7fb5cf",
   "metadata": {},
   "source": [
    "### nn.Sequential\n",
    "\n",
    "[nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) es un contenedor ordenado\n",
    "de módulos. Los datos se pasan a través de todos los módulos en el mismo orden en que se definen. Puedes usar\n",
    "contenedores secuenciales para armar rápidamente una red como ``seq_modules``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3153c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36aec6a",
   "metadata": {},
   "source": [
    "### nn.Softmax\n",
    "\n",
    "La última capa lineal de la red neuronal devuelve `logits` - valores sin procesar en [-∞, ∞] - que se pasan al\n",
    "módulo [nn.Softmax](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html). Los logits se escalan a valores\n",
    "[0, 1] que representan las probabilidades predichas del modelo para cada clase. El parámetro ``dim`` indica la dimensión a lo largo de\n",
    "la cual los valores deben sumar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f9127",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "pred_probab*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2af155",
   "metadata": {},
   "source": [
    "## Parámetros del Modelo\n",
    "\n",
    "Muchas capas dentro de una red neuronal están *parametrizadas*, es decir, tienen pesos\n",
    "y sesgos asociados que se optimizan durante el entrenamiento. Heredar de ``nn.Module`` automáticamente\n",
    "rastrea todos los campos definidos dentro de tu objeto modelo, y hace que todos los parámetros\n",
    "sean accesibles usando los métodos ``parameters()`` o ``named_parameters()`` de tu modelo.\n",
    "\n",
    "En este ejemplo, iteramos sobre cada parámetro, e imprimimos su tamaño y una vista previa de sus valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f1719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62435a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lectura Adicional\n",
    "\n",
    "- [torch.nn API](https://pytorch.org/docs/stable/nn.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50475a06",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "Los tensores son una estructura de datos especializada similar a los arreglos y matrices.\n",
    "En PyTorch, usamos tensores para codificar las entradas y salidas de un modelo, así como los parámetros del modelo.\n",
    "\n",
    "Los tensores son similares a los ndarrays de [NumPy](https://numpy.org/), excepto que los tensores pueden ejecutarse en GPUs u otros aceleradores de hardware. De hecho, los tensores y los arreglos de NumPy a menudo pueden compartir la misma memoria subyacente, eliminando la necesidad de copiar datos. Los tensores también están optimizados para diferenciación automática (veremos más sobre eso más adelante en la sección [Autograd](autogradqs_tutorial.html)). Si estás familiarizado con ndarrays, te sentirás como en casa con la API de Tensores. ¡Si no, sigue adelante!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a2d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479eaa1b",
   "metadata": {},
   "source": [
    "## Inicializar un Tensor\n",
    "\n",
    "Los tensores pueden ser inicializados de varias maneras. Echa un vistazo a los siguientes ejemplos:\n",
    "\n",
    "### Directamente desde datos\n",
    "\n",
    "Los tensores pueden ser creados directamente desde datos. El tipo de dato se infiere automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4978bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "x_data.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb641b49",
   "metadata": {},
   "source": [
    "### Desde un arreglo NumPy\n",
    "\n",
    "Los tensores pueden ser creados desde arreglos NumPy (y viceversa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d947a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e79b9a",
   "metadata": {},
   "source": [
    "### Desde otro tensor:\n",
    "\n",
    "El nuevo tensor mantiene las propiedades (forma, tipo de dato) del tensor argumento, a menos que se anule explícitamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a869df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ones = torch.ones_like(x_data) # mantiene las propiedades de x_data\n",
    "print(f\"Tensor de Unos: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # anula el tipo de dato de x_data\n",
    "print(f\"Tensor Aleatorio: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a3ab56",
   "metadata": {},
   "source": [
    "### Con valores aleatorios o constantes:\n",
    "\n",
    "Para el siguiente ejemplo ``shape`` es una tupla de dimensiones del tensor. En las funciones de abajo, determina la dimensionalidad del tensor de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752580a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Tensor Aleatorio: \\n {rand_tensor} \\n\")\n",
    "print(f\"Tensor de Unos: \\n {ones_tensor} \\n\")\n",
    "print(f\"Tensor de Ceros: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b6cc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Atributos de un Tensor\n",
    "\n",
    "Los atributos del tensor describen su forma, tipo de dato y el dispositivo en el que están almacenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baca37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Forma del tensor: {tensor.shape}\")\n",
    "print(f\"Tipo de dato del tensor: {tensor.dtype}\")\n",
    "print(f\"Dispositivo donde está almacenado el tensor: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd61a2be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Operaciones en Tensores\n",
    "\n",
    "PyTorch contiene más de 1200 operaciones de tensores, incluyendo aritmética, álgebra lineal, manipulación de matrices (transponer,\n",
    "indexar, rebanar), muestreo y más, las cuales están descritas exhaustivamente [aquí](https://pytorch.org/docs/stable/torch.html).\n",
    "\n",
    "Cada una de estas operaciones puede ejecutarse en la CPU y en [Acelerador](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
    "como CUDA, MPS, MTIA, o XPU. Al usar Colab, asigna un acelerador yendo a Runtime > Change runtime type > GPU.\n",
    "\n",
    "Por defecto, los tensores se crean en la CPU. Necesitamos mover explícitamente los tensores al acelerador usando\n",
    "el método ``.to`` (después de verificar la disponibilidad del acelerador). Ten en cuenta que copiar tensores grandes\n",
    "entre dispositivos puede ser costoso en términos de tiempo y memoria!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad77c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movemos nuestro tensor al acelerador actual si está disponible\n",
    "if torch.accelerator.is_available():\n",
    "    tensor = tensor.to(torch.accelerator.current_accelerator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7038d04",
   "metadata": {},
   "source": [
    "A continuación se muestran algunas de las operaciones de la lista.\n",
    "Si estás familiarizado con la API de NumPy, encontrarás que la API de Tensores es muy fácil de usar.\n",
    "\n",
    "### Indexación y rebanado (slicing) estándar tipo numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99209772",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"Primera fila: {tensor[0]}\")\n",
    "print(f\"Primera columna: {tensor[:, 0]}\")\n",
    "print(f\"Última columna: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979e40cf",
   "metadata": {},
   "source": [
    "### Unir tensores\n",
    "\n",
    "Puedes usar ``torch.cat`` para concatenar una secuencia de tensores a lo largo de una dimensión dada.\n",
    "Existe otro oeprador de union llamadao [torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html), que es sutilmente diferente de ``torch.cat``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7bef174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ad7b9",
   "metadata": {},
   "source": [
    "### Operaciones aritméticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c268cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto calcula la multiplicación de matrices entre dos tensores usando matmul o su función equivalente @. \n",
    "# y1, y2, y3 tendrán el mismo valor\n",
    "# ``tensor.T`` devuelve la transpuesta de un tensor\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(tensor, tensor.T, out=y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c92e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esto calcula el producto elemento por elemento. z1, z2, z3 tendrán el mismo valor\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d0683",
   "metadata": {},
   "source": [
    "### Tensores de un solo elemento\n",
    "\n",
    "Si tienes un tensor de un elemento, por ejemplo despues de sumar todos los valores de un mismo tensor, puedes convertirlo a un valor numérico de Python usando ``item()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce50b460",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56fa348",
   "metadata": {},
   "source": [
    "### Operaciones in-place\n",
    "\n",
    "Las operaciones que almacenan el resultado en el mismo lugar (operando) se llaman in-place. Se denotan con un sufijo ``_``.\n",
    "Por ejemplo: ``x.copy_(y)``, ``x.t_()``, cambiarán el contenido de ``x``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b031b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf41ebf",
   "metadata": {},
   "source": [
    "**Nota:**\n",
    "Las operaciones in-place ahorran algo de memoria, pero pueden ser problemáticas al calcular derivadas debido a una pérdida inmediata\n",
    "del historial. Por lo tanto, se desaconseja su uso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a119b7",
   "metadata": {},
   "source": [
    "## Puente con NumPy\n",
    "\n",
    "Los tensores en la CPU y los arreglos NumPy pueden compartir sus ubicaciones de memoria subyacente,  de manera que cambiar los valores de uno cambiará los valores del otro.\n",
    "\n",
    "### Tensor a arreglo NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf7dedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e5d485",
   "metadata": {},
   "source": [
    "Un cambio en el tensor se refleja en el arreglo NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f26b07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df16f0f",
   "metadata": {},
   "source": [
    "### Arreglo NumPy a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bece090",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6b399c",
   "metadata": {},
   "source": [
    "Los cambios en el arreglo NumPy se reflejan en el tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c55bae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

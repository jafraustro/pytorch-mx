{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e35eea",
   "metadata": {},
   "source": [
    "# Inicio Rápido\n",
    "\n",
    "Esta sección muestra a grandes rasgos la (Application Progrsamming Interface) API para tareas comunes en aprendizaje automático. Consulta los enlaces en cada sección para profundizar al respecto.\n",
    "\n",
    "## Trabajando con datos\n",
    "\n",
    "PyTorch tiene dos [primitivas para trabajar con datos](https://pytorch.org/docs/stable/data.html):\n",
    "``torch.utils.data.DataLoader`` y ``torch.utils.data.Dataset``.\n",
    "``Dataset`` almacena las muestras y sus etiquetas correspondientes, y ``DataLoader`` envuelve un iterable alrededor\n",
    "del ``Dataset``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a092fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acef74",
   "metadata": {},
   "source": [
    "PyTorch ofrece bibliotecas específicas de dominio como [TorchVision](https://pytorch.org/vision/stable/index.html) y [TorchAudio](https://pytorch.org/audio/stable/index.html), las cuales incluyen conjuntos de datos para tareas de visión por computadora o manipulación de audio respectivamente. Para este tutorial, usaremos un conjunto de datos de TorchVision.\n",
    "\n",
    "El módulo ``torchvision.datasets`` contiene objetos ``Dataset`` para muchos sets de visión del mundo real como\n",
    "CIFAR, COCO ([lista completa aquí](https://pytorch.org/vision/stable/datasets.html)). En este tutorial, usamos\n",
    "el conjunto de datos FashionMNIST. Cada ``Dataset`` de TorchVision incluye dos argumentos: ``transform`` y\n",
    "``target_transform`` para modificar las muestras y etiquetas respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faadcfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar datos de entrenamiento de conjuntos de datos abiertos.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Descargar datos de prueba de conjuntos de datos abiertos.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68abbbdb",
   "metadata": {},
   "source": [
    "Se pasa el ``Dataset`` como un argumento al objeto/método ``DataLoader``. Esto \"envuelve\" el dataset en un iterador (iterable) que soporta la generación automática de lotes (batches) así como muestreo (sampling), mezclado (shuffling) y la carga de datos multiproceso.\n",
    "En el siguiente ejemplo se define un tamaño de lote de 64, con lo que cada elemento del iterador que conforma el dataloader regresara un lote de 64 características y etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb868eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073888d1",
   "metadata": {},
   "source": [
    "Lee más sobre [cargar datos en PyTorch](data_tutorial.html).\n",
    "\n",
    "---\n",
    "\n",
    "## Creando Modelos\n",
    "\n",
    "Para definir una red neuronal en PyTorch, creamos una clase que hereda\n",
    "de [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Definimos las capas de la red\n",
    "en la función ``__init__`` y especificamos cómo los datos pasarán a través de la red en la función ``forward``. Para acelerar\n",
    "las operaciones en la red neuronal, la movemos al [acelerador](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
    "como CUDA, MPS, MTIA, o XPU. Si el acelerador actual está disponible, lo usaremos. De lo contrario, usamos la CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4511a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae50626",
   "metadata": {},
   "source": [
    "Lee más sobre [construir redes neuronales en PyTorch](buildmodel_tutorial.html).\n",
    "\n",
    "---\n",
    "\n",
    "## Optimizando los Parámetros del Modelo\n",
    "\n",
    "Para entrenar un modelo, necesitamos una [función de pérdida](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "y un [optimizador](https://pytorch.org/docs/stable/optim.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc5d21c",
   "metadata": {},
   "source": [
    "En un único ciclo de entrenamiento, el modelo hace predicciones sobre el conjunto de datos de entrenamiento (alimentado en lotes), y\n",
    "retropropaga el error de predicción para ajustar los parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Calcular error de predicción\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Retropropagación\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"pérdida: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a9e2e4",
   "metadata": {},
   "source": [
    "También verificamos el rendimiento del modelo contra el conjunto de datos de prueba para asegurar que está aprendiendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Error de Prueba: \\n Precisión: {(100*correct):>0.1f}%, Pérdida promedio: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc8566",
   "metadata": {},
   "source": [
    "El proceso de entrenamiento se lleva a cabo a lo largo de varias iteraciones (*épocas*). Durante cada época, el modelo aprende\n",
    "parámetros para hacer mejores predicciones. Imprimimos la precisión y la pérdida del modelo en cada época; buscando que la\n",
    "precisión aumente y la pérdida disminuya con cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Época {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"¡Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5dc168",
   "metadata": {},
   "source": [
    "Lee más sobre [Entrenar tu modelo](optimization_tutorial.html).\n",
    "\n",
    "---\n",
    "\n",
    "## Guardar Modelos\n",
    "\n",
    "Una forma común de guardar un modelo es serializar el diccionario de estado interno (que contiene los parámetros del modelo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c13b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Estado del Modelo PyTorch guardado en model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524d95a",
   "metadata": {},
   "source": [
    "## Cargar Modelos\n",
    "\n",
    "El proceso para cargar un modelo incluye recrear la estructura del modelo y cargar\n",
    "el diccionario de estado en él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd5349",
   "metadata": {},
   "source": [
    "Este modelo ahora puede ser usado para hacer predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc918081",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"Camiseta/top\",\n",
    "    \"Pantalón\",\n",
    "    \"Suéter\",\n",
    "    \"Vestido\",\n",
    "    \"Abrigo\",\n",
    "    \"Sandalia\",\n",
    "    \"Camisa\",\n",
    "    \"Zapatilla\",\n",
    "    \"Bolsa\",\n",
    "    \"Bota\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicción: \"{predicted}\", Real: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d6034",
   "metadata": {},
   "source": [
    "Lee más sobre [Guardar y Cargar tu modelo](saveloadrun_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d83fd",
   "metadata": {},
   "source": [
    "### Representación gráfica de la inferencia del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las primeras 4 imágenes de los conjuntos de datos de entrenamiento y prueba\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Crear subgráficas para los datos de entrenamiento\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "fig.suptitle('Conjunto de Datos Fashion-MNIST - Primeras 4 Imágenes', fontsize=16)\n",
    "\n",
    "# Mostrar las primeras 4 imágenes de entrenamiento\n",
    "for i in range(4):\n",
    "    image, label = training_data[i]\n",
    "    axes[0, i].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[0, i].set_title(f'Entrena: {classes[label]}')\n",
    "    axes[0, i].axis('off')\n",
    "\n",
    "# Mostrar las primeras 4 imágenes de prueba\n",
    "for i in range(4):\n",
    "    image, label = test_data[i]\n",
    "    axes[1, i].imshow(image.squeeze(), cmap='gray')\n",
    "    axes[1, i].set_title(f'Prueba: {classes[label]}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir detalles de las imágenes\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(training_data)}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(test_data)}\")\n",
    "print(f\"Forma de la imagen: {training_data[0][0].shape}\")\n",
    "print(f\"Número de clases: {len(classes)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
